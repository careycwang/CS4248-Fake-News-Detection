{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0e813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b2ad9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_train = pd.read_csv(\"./data/fulltrain.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1829cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_test =pd.read_csv(\"./data/balancedtest.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c02531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b58fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(x):\n",
    "    x = x.lower() # lower case\n",
    "    tokens = tokenizer.tokenize(x)\n",
    "    # remove stopwords and punctuations\n",
    "    filtered = [lemmatizer.lemmatize(i) for i in tokens if i not in stopwords.words()]\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cafba19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train[\"processed\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "idxs = full_train.index\n",
    "for i in range(0,len(idxs)):\n",
    "    if i % 500 == 0 and i != 0:\n",
    "      print(\"Number of rows processed: \" + str(i))\n",
    "    full_train.loc[idxs[i],\"processed\"] = process_text(full_train.loc[idxs[i],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced test set\n",
    "idxs = balanced_test.index\n",
    "for i in range(0,len(idxs)):\n",
    "    if i % 500 == 0 and i != 0:\n",
    "      print(\"Number of rows processed: \" + str(i))\n",
    "    balanced_test.loc[idxs[i],\"processed\"] = process_text(balanced_test.loc[idxs[i],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a549be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.to_csv(\"full_train_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea0e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_test.to_csv(\"balanced_test_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
